{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9eb06a",
   "metadata": {},
   "source": [
    "# <span style=\"color: #26B260\"> Comparaison de deux paramètres statistiques - variances, moyennes et proportions - de séries indépendantes. </span>\n",
    "\n",
    "Dans le monde de l'analyse de données, la comparaison de deux paramètres statistiques tels que les moyennes ou les proportions est une tâche courante et cruciale pour tirer des conclusions éclairées. Les outils de programmation comme R et Python offrent des fonctionnalités puissantes et flexibles pour effectuer ces comparaisons. Cet article se propose de vous guider à travers les étapes nécessaires pour comparer des moyennes ou des proportions en utilisant ces deux langages populaires. Que vous soyez débutant ou analyste confirmé, vous découvrirez des méthodes pratiques et des exemples concrets pour maîtriser cette compétence essentielle en statistiques.\n",
    "\n",
    "Dans de nombreux domaines, de l'industrie, de la banque, de la finance et de l'assurance, du marketing et plus générallement en économie et en gestion, l'interprétation d'une différence - de proportion, de moyenne ou de variance- observée entre deux échantillons est essentielle. Notammant, **cette différence observée peut-elle être généralisée à l'ensemble des populations ou n'est elle que le fait d'une simple fluctuation d'échantillonage ?** La réponse à cette question doit être éclairée par une **analyse inférentielle** afin d'apporter une aide à la décision efficiente.\n",
    "\n",
    "Comme nous venons de le mentionner, et pour le formuler différement, s'intéresser à **comparer deux paramètres statistiques** de **deux échantillons indépendants** revient à se demander si **les deux échantillons sont issus de la même population**. Il s'agit donc de mener une analyse de type inférentielle afin de savoir s'il est possible de **généraliser l'étude des échantillons à l'échelle des populations**. En outre, puisque nous souhaitons savoir si les échantillons indépendants sont issus de la même population, nous effectuerons un **test d'homogénéité**. \n",
    "\n",
    "Alors, comment procéder à la mise en place d'une telle analyse ?\n",
    "Une **analyse inférentille** suppose la réalisation d'un test statistique et donc de poser des hypothèses - hypthèse nulle et hypothèse alternative. Puis, en calculant une statistique de test appropriée, à calculer la probabilité d'observer la différence (de variance, de moyenne ou de proportion) sous l'hypothèse nulle -i.e. si l'hypothèse nulle est vraie. Cette dernière étape permettra d'infirmer ou non l'hypothèse nulle au profit de l'hyothèse alternative, comtpe tenu d'un seuil de risque $\\alpha$ (très souvent fixé à 5%). Attention toutefois à la conclusion que vous apporterez : il n'est possible de conclure qu'à la différence des deux paramètres statistiques. En effet, puisque le test est réalisé sous l'hypothèse nulle, cette dernière peut être rejetée au profit de l'hypothèse alternative. A l'inverse, le non-rejet de l'hypothèse nulle ne dit rien quant à l'égalité des paramètres statistiques puisqu'une telle conclusion impliquerait de tester notre statistique de test sous l'hypothèse alternative - cf. test d'équivalence. Aussi, si l'hypothèse nulle ne peut être rejetée -i.e. p-value > 0.05 - c'est que l'on manque d'évidence pour conclure à une différence statistiquement significative. Pourquoi conclu-t-on que l'on manque d'évidence ? Pour la bonne raison que le non rejet de l'hypothèse nulle n'est pas forcément la cause d'une absence d'effet mais peut être du à une faible puissance statistique. Alors le test d'équivalence peut s'avérer utile pour soustraire au champ des possibles une éventuelle absence d'effet. \n",
    "\n",
    "À ce sujet, n'hésitez pas à consulter [ma note](https://docs.framasoft.org/fr/grav/). (ajout lien vers repo git).\n",
    "\n",
    "\n",
    "Maintenant que les principes de base des tests statistiques et de l'analyse inférentielle ont été rappelés, allons explorer le monde passionant des tests d'homogénéité. Dans un premier temps nous evoquerons le test de comparaison de deux variances. Puis, nous étudierons les tests de comparaisons de deux moyennes. Nous profiterons de cette seconde partie pour rappeler la différence et l'importance d'utiliser des tests non-paramétriques. Enfin, la troisième et dernière partie de ce billet nous présentera les tests de comparaison de deux proportions. \n",
    "\n",
    "Permettez-moi d'insister sur l'objet pedagogique de cette note. Pour cette raison, des exemples simples, avec des données fictives, seront développés après chaque partie. Notamment, une implémentation en python et en R vous sera présentée pour chacun des tests mentionnés. \n",
    "\n",
    "Attachez vos cinture! En avant pour les méandres de la statistique! \n",
    "\n",
    "\n",
    "\n",
    "## Comparaison de deux variances.\n",
    "    Peut-on considérer, avec un risque d'erreur donné, que les variances de deux échantillons indépendants sont identiques ?\n",
    "    Pour l'écrire différement, la différence de variance observée est-elle dûe au hasard - i.e. à de simples fluctuations d'échantillonage ?\n",
    "\n",
    "Il est courant de s'intéresser à la variabilité de deux échantillons indépendants. Notamment, vous pouvez vous demander si les risques associés à deux portefeuilles d'actions sont égalaux (comparer la volatilité sur les marchés financiers), ou si la répartition des salaires entre les hommes et les femmes diffère (comparer la variabilité des salaires entre les hommes et les femmes, à poste équivalent). De plus, un test d'égalité des variances est très utile dans l'industrie pour le contrôle qualité. Par exemple, comparer la durée de vie des composants ou des matières premières, comparer les temps de production, évaluer la resistance des produits finis et indentifier des machines défectueuses. \n",
    "\n",
    "Pour ce faire un test existe, le test F de Fisher-Snedecor. Ce test va permettre de comparer les variances de deux échantillons indépendants et normalement distribués. Ce test est donc **paramétrique** puisqu'il suppose les données normalement distribuées. Dans le cas présent il n'existe pas d'alternative non-paramétrique. Souvent, et à tord, les test de Bartlett, de Levene et de Fligner-Killen sont cités comme étant des alternatives. Toutefois, l'ensemble de ces tests compare les variances des $k$ groupes d'une variable catégorielle. Aussi, ces tests sont une alternative pour tester l'homogénéité des variances dans le cadre d'une ANOVA, par exemple, mais ne sont pas une alternative au  test F d'homogénéité de variance - ces tests feront donc l'objet d'un prochain billet relatif à l'[ANOVA à un facteur] (lien vers mon repo-git). \n",
    "\n",
    "Revenons à nos moutons! Un test statistique, nous l'avons dit, c'est un jeu d'hypothèse, une statistique de test et un seuil de significativité $\\alpha$.  \n",
    "\n",
    "Premièrement, posons les hypothèses de travail d'un test bilatéral. L'hypothèse nulle stipule que les variances sont homogènes - i.e. la différence de variance observée est due à une simple fluctuation d'échantillonage. L'hypothèse alternative suppose que les variances ne sont pas homogènes - i.e. les deux échantillons ne proviennent pas de la même population. \n",
    "\n",
    "- H0 : $\\sigma^2_1 = \\sigma^2_2;$\n",
    "- H1 : $\\sigma^2_1 \\neq \\sigma^2_2.$\n",
    "\n",
    "Selon le cas d'usage, il peut être nécessaire de mettre en plance un test unilatéral à gauche (à droite). Dans quel cas, l'hypothèse alternative sera modifiée telle que : $\\sigma^2_1 < \\sigma^2_2$ ($\\sigma^2_1 > \\sigma^2_2$). \n",
    "\n",
    "Une fois le jeu des hypothèses déterminés, nous pouvons définir la statistique de test appropriée.  \n",
    "\n",
    "### <span style=\"color: #FF8333\"> Le test F de Fisher-Snedecor. </span> \n",
    "\n",
    "Posons la statistique de test du F :\n",
    "\n",
    "$F = \\dfrac{\\sigma^2_1}{\\sigma^2_2}$\n",
    "\n",
    "Il est claire que cette statistique de test suit une **loi de Fisher-Snedecor**. En effet, la statistique $F$ est le **rapport de deux variables aléatoires indépendantes suivant chacune une loi du khi²** (somme de carrées de varaiables aléatoires indépendantes suivant une loi normal) et **divisées par leur nombre de degrés de liberté (ddl)**.\n",
    "\n",
    "Il s'agit donc de calculer cette statistique de test puis de la comparer au quantile de la table de Fisher pour un risque choisi $\\alpha$ et deux nombres de degré de liberté (ddl) - $ddl_1 = n_1 -1$, $ddl_2 = n_2 - 1$. \n",
    "\n",
    "#### <span style=\"color: #FDC82F\"> Conditions d'application du test F de Fisher-Snedecor. </span> \n",
    "L'application de ce test nécessite la normalité des échantillons. Pour vérifier la distribution normale des échantillons il faut toujours mener une analyse graphique afin de détecter d'éventuels défauts de normalités ; la réalisation d'un test statistique d'adéquation - e.g. Shapiro Wilk - n'est pas suffisante. \n",
    "\n",
    "Voici comment effectuer le test d'homogénéité des variances de Fisher avec la bibliothèque standard de $R$ :\n",
    "```R\n",
    "test_F = var.test(Sepal.Length~Species, data=iris[1:100,], paired=FALSE)\n",
    "summary(test_F)\n",
    "```\n",
    "\n",
    "Avec python, plusieurs packages statistiques existent - Scipy, Statsmodels, Pingouin. A ma connaissance, seul le module scipy.stats fourni un test F. Notons que ce test ne peut être réalisé que pour des échantillons indépendants et normalement distribués. \n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def F_test(series_1, series_2):\n",
    "    \"\"\"\n",
    "    This function implements a F test for testing homogeneity of two normaly distributed and independent variable.\n",
    "    \n",
    "    Args :\n",
    "     - series_1 and series_2 : series of the two distribution to be compared.\n",
    "    Returns :\n",
    "     - results (pd.DataFrame) : a dataframe reporting the results : ddf1, ddf2, f statistic and p-value. \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the sample variances\n",
    "    # We substract 1 to the denominator N since we are working with samples' variance : ddof=1.\n",
    "    variance1 = np.var(series_1, ddof=1)\n",
    "    variance2 = np.var(series_2, ddof=1) \n",
    "\n",
    "    # Calculate the F-statistic\n",
    "    f_value = variance1 / variance2\n",
    "\n",
    "    # Calculate the degrees of freedom\n",
    "    df1 = len(series_1) - 1\n",
    "    df2 = len(series_2) - 1\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = stats.f.cdf(f_value, df1, df2)\n",
    "\n",
    "    # Print the results\n",
    "    results = pd.DataFrame(index=['Degree of freedom 1', 'Degree of freedom 2', 'F-statistic', 'p-value'], columns = [f\"{serie_1}/{serie_2}\"], data = [[df1, df2, f_value, p_value]])\n",
    "    \n",
    "    if pvalue < 0.05:\n",
    "        print(f\"L'hypothèse nulle est rejetée au profit de l'hypothèse alternative : {pvalue} < 0.05. \\n Les variances ne sont pas homogènes\", results)\n",
    "    else:\n",
    "        print(f\"Nous ne pouvons pas rejeter l'hypothèse nulle, {pvalue} > 0.05. En outre, rien ne permet de conclure à l'absence de différence.\", results)\n",
    "        \n",
    "    return results \n",
    "\n",
    "\n",
    "results = F_test(serie_1, serie_2)\n",
    "display(results)\n",
    "\n",
    "```\n",
    "\n",
    "**Pour représenter graphiquement une distribution de Fisher-Senedecor, voir : https://www.geeksforgeeks.org/how-to-perform-an-f-test-in-python/. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4771402",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5655/2761152229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    451\u001b[0m \"\"\"\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_measurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m from scipy._lib._util import (check_random_state, MapWrapper,\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/spatial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \"\"\"\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_kdtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ckdtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_qhull\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/spatial/_kdtree.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ckdtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcKDTreeNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m __all__ = ['minkowski_distance_p', 'minkowski_distance',\n",
      "\u001b[0;32m_ckdtree.pyx\u001b[0m in \u001b[0;36minit scipy.spatial._ckdtree\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def F_test(serie_1, serie_2):\n",
    "    \"\"\"\n",
    "    This function implements a F test for testing homogeneity of two normaly distributed and independent variable.\n",
    "    \n",
    "    Args :\n",
    "     - series_1 and series_2 : series of the two distribution to be compared.\n",
    "    Returns :\n",
    "     - results (pd.DataFrame) : a dataframe reporting the results : ddf1, ddf2, f statistic and p-value. \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the sample variances\n",
    "    # We substract 1 to the denominator N since we are working with samples' variance : ddof=1.\n",
    "    variance1 = np.var(serie_1, ddof=1)\n",
    "    variance2 = np.var(serie_2, ddof=1) \n",
    "\n",
    "    # Calculate the F-statistic\n",
    "    f_value = variance1 / variance2\n",
    "\n",
    "    # Calculate the degrees of freedom\n",
    "    df1 = len(serie_1) - 1\n",
    "    df2 = len(serie_2) - 1\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = stats.f.cdf(f_value, df1, df2)\n",
    "\n",
    "    # Print the results\n",
    "    results = pd.DataFrame(index=['Degree of freedom 1', 'Degree of freedom 2', 'F-statistic', 'p-value'], \n",
    "                           columns = [f\"{serie_1}/{serie_2}\"], data = [[df1, df2, f_value, p_value]])\n",
    "    \n",
    "    if pvalue < 0.05:\n",
    "        print(f\"L'hypothèse nulle est rejetée au profit de l'hypothèse alternative : {p_value} < 0.05. \\n Les variances ne sont pas homogènes\", results)\n",
    "    else:\n",
    "        print(f\"Nous ne pouvons pas rejeter l'hypothèse nulle, {p_value} > 0.05. En outre, rien ne permet de conclure à l'absence de différence.\", results)\n",
    "        \n",
    "    return results \n",
    "\n",
    "\n",
    "results = F_test(serie_1, serie_2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd21576",
   "metadata": {},
   "source": [
    "Voilà, ce billet touche à sa fin! J'espère qu'il vous a aidé. **Merci pour votre lecture.**\n",
    "\n",
    "N'hésitez pas à m'écrire si vous avez des remarques ou des questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7507b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
